---
{"dg-publish":true,"permalink":"/Code/4.OS/OS.0c.进程管理/","title":"进程管理","noteIcon":""}
---


# 进程管理

> [5.1 进程、线程基础知识 | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/os/4_process/process_base.html)

## 进程

进程是 CPU 中运行的一个程序

### 运行状态

在一个进程的活动期间至少具备三种基本状态，即**运行状态、就绪状态、阻塞状态**
- 运行状态(_Running_)：该时刻进程占用 CPU
- 就绪状态(_Ready_)：进程可运行，但由于其他进程处于运行状态而暂时停止运行
- 阻塞状态(_Blocked_）：进程正在等待某一事件发生(如等待 I/O 操作的完成)而暂时停止运行，这时即使得到 CPU 控制权该进程也无法运行

进程还有另外两个基本状态：
- 创建状态(_New_)：进程正在被创建时的状态
- 结束状态(_Exit_)：进程正在从系统中消失时的状态

在操作系统的虚拟内存管理中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存
挂起状态用于描述进程没有占用实际的物理内存空间的情况，同时又分为两种：
- 阻塞挂起状态：进程在外存(硬盘)并等待某个事件的出现
- 就绪挂起状态：进程在外存(硬盘)，但只要进入内存，即刻立刻运行

> ![10-进程七中状态.jpg (1166×722) (xiaolincoding.com)](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg)

### 控制结构

操作系统中用*进程控制块*(PCB)数据结构来描述进程

**PCB 是进程存在的唯一标识**，包含以下信息
- 进程描述信息
  - 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符
  - 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务
- 进程控制和管理信息
  - 进程当前状态，如 new、ready、running、waiting 或 blocked 等
  - 进程优先级：进程抢占 CPU 时的优先级
- 资源分配清单
  - 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息
- CPU 相关信息：
  - CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行

操作系统以*链表*的形式连接 PCB 对**状态相同**的进程进行管理

### 控制过程

#### 创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源
创建进程的过程如下：
1. 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等
2. 为该进程分配运行时所必需的资源，比如内存资源
3. 将 PCB 插入到就绪队列，等待被调度运行

#### 终止进程

进程可以有 3 种终止方式：正常结束、异常结束以及外界干预(信号 kill 掉)

当子进程被终止时，其在父进程处继承的资源应当还给父进程
而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作

终止进程的过程如下：
1. 查找需要终止的进程的 PCB
2. 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程
3. 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管
4. 将该进程所拥有的全部资源都归还给操作系统
5. 将其从 PCB 所在队列中删除

#### 阻塞进程

当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

阻塞进程的过程如下：
1. 找到将要被阻塞进程标识号对应的 PCB
2. 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行
3. 将该 PCB 插入到阻塞队列中去

#### 唤醒进程

进程由*运行*转变为*阻塞*状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它

唤醒进程的过程如下：
1. 在该事件的阻塞队列中找到相应进程的 PCB
2. 将其从阻塞队列中移出，并置其状态为就绪状态
3. 把该 PCB 插入到就绪队列中，等待调度程序调度

进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句

### 上下文切换

进程是由内核管理和调度的，所以进程的切换只能发生在内核态
进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源

切换场景：
- 当某个进程的 CPU 时间片耗尽时，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行
- 进程在系统资源不足(比如内存不足)时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，也会重新调度
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序

### Linux 进程通信

每个进程的用户地址空间相互独立的，通常不能互相访问，所有进程共享内核空间，因此**进程之间必须通过内核进行通信**

#### 管道

linux 可直接使用 `|` 作为**匿名管道**进行单向传输数据
```bash
ps auxf | grep mysql
```

或者采用 `mkfifo` 创建数据先进先出的**命名管道**

当向管道中写入数据时进程阻塞，直到另一进程从管道中读取数据

管道实际为内核中的一段缓存，传输的数据是无格式的流且大小受限

#### 消息队列

**消息队列是保存在内核中的消息链表**，传输的数据为用户自定义的数据类型**消息体**

进程异步写入消息队列后正常返回，另一进程需要时从消息队列中读取数据

缺点：
- 消息体大小受限，消息队列最大长度受限
- 通信过程中发生用户态和内核态之间的数据拷贝开销

#### 共享内存

使用一块虚拟地址空间映射至相同的物理内存中
> ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/9-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98.jpg)

#### 信号量

**信号量是一个整型的计数器**，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据

信号量表示资源的数量，控制信号量的方式有两种**原子操作**：
- **P 操作**：把信号量减去 1
  - 相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待
  - 相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行
- **V 操作**：把信号量加上 1
  - 相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行
  - 相加后如果信号量 > 0，则表明当前没有阻塞中的进程

#### 信号

**对于异常情况下的工作模式，用信号的方式来通知进程**
Linux 操作系统中为了响应各种各样的事件，提供了多种信号
```bash
$ kill -l
HUP INT QUIT ILL TRAP IOT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS
```

信号是进程间通信机制中**唯一的异步通信机制**，可以在任何时候发送信号给某一进程
一旦信号产生，有以下几种用户进程对信号的处理方式：
- **执行默认操作** - Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号执行终止进程
- **捕捉信号** - 可以为信号定义一个信号处理函数，当信号发生时执行相应的信号处理函数
- **忽略信号** - 当不希望处理某些信号时可以忽略该信号不做任何处理，有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程

#### Socket

Socket 用于跨网络与不同主机上的进程通信

创建 socket 的系统调用：

```C
int socket(int domain, int type, int protocal)
```
- domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机
- type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字
- protocal 参数原本是用来指定通信协议的，但现在基本废弃，因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可

**针对 TCP 协议通信的 socket 编程模型**
>![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/12-TCP%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg)

1. 服务端和客户端初始化用于监听的 `socket`，得到文件描述符
2. 服务端调用 `bind`，将用于监听的 `socket` 绑定在 IP 地址和端口
3. 服务端调用 `listen` 进行监听
4. 服务端调用 `accept` 等待客户端连接
5. 客户端调用 `connect` 向服务器端的地址和端口发起连接请求
6. 服务端 `accept` 返回用于传输的 `socket` 的文件描述符
7. 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据
8. 客户端断开连接时调用 `close`
9. 服务端 `read` 读取数据时读取到 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭

**针对 UDP 协议通信的 socket 编程模型**

> ![13-UDP编程模型.jpg (513×671) (xiaolincoding.com)](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/13-UDP%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg)

对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind

另外，每次通信调用 `sendto` 和 `recvfrom` 时都要传入目标主机的 IP 地址和端口。

**针对本地进程间通信的 socket 编程模型**

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是**绑定一个本地文件**，这也就是它们之间的最大区别

## 线程

**线程是进程当中的一条执行流程**

同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的

### 实现

主要有三种线程的实现方式：
- **用户线程**：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理
- **内核线程**：在内核中实现的线程，是由内核管理的线程
- **轻量级进程**：在内核中支持用户线程

#### 用户线程

用户线程基于用户态的线程管理库实现，线程控制块(TCB)也在库里实现，对于操作系统不可见，操作系统只能看到整个进程的 PCB

用户级线程的模型下多个用户线程对应同一个内核线程

优点
- 每个进程都需要有私有的线程控制块(TCB)列表，用来跟踪记录该进程中各个线程的状态信息(PC、栈指针、寄存器)，TCB 由用户级线程库函数维护，可用于不支持线程技术的操作系统
- 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快

缺点
- 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行
- 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的
- 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢

#### 内核线程

内核线程由操作系统管理，线程对应的 TCB 位于操作系统中，线程的创建、终止和管理都由操作系统负责

内核线程的模型下一个用户线程对应一个内核线程

优点
- 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，不会影响其他内核线程的运行
- CPU 时间片分配给线程，多线程的进程获得更多的 CPU 运行时间

缺点
- 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB，由于内核线程运行在内核态，每次在内核态与用户态切换时，需要进行上下文切换。这种切换开销比较大，会降低内核线程的性能
- 线程的创建、终止和切换都是通过系统调用的方式来进行，系统需要维护一张内核线程表，实时维护每个线程的状态。每次调度线程时，需要进行复杂的处理和判断，开销比较大

#### 轻量级进程

轻量级进程(LWP)是是一种由内核支持的用户线程，是基于内核线程的高级抽象，只有先支持内核线程，才能有 LWP，一个进程可有一个或多个 LWP，每个 LWP 都由一个内核线程支持，跟内核线程一对一映射，且 LWP 由内核管理，并像普通进程一样被调度

在大多数系统中，**LWP 与普通进程的区别在于它只有一个最小的执行上下文和调度程序所需的统计信息**
一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这些信息

缺点
- 大多数 LWP 的操作，如建立、析构以及同步，都需要进行系统调用。系统调用的代价相对较高：需要在用户态和内核态中切换
- 每个 LWP 都需要有一个内核线程支持，因此 LWP 要消耗内核资源(内核线程的栈空间)。因此一个系统不能支持大量的 LWP

在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：
- `1 : 1`，即一个 LWP 对应一个用户线程
  - 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP
  - 缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大
- `N : 1`，即一个 LWP 对应多个用户线程
  - 优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高
  - 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的
- `M : N`，即多个 LWP 对应多个用户线程
  - 优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源
- 组合，结合 `1:1` 模型和 `M:N` 模型，开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案

> ![22-LWP.jpg (1788×1088) (xiaolincoding.com)](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/22-LWP.jpg)

### 上下文切换

当两个线程不属于同一个进程，则切换的过程跟进程上下文切换一样
当两个线程属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源保持不动，只需要切换线程的私有数据、寄存器等不共享的数据

### 多线程

同一进程下的多线程之间可以共享进程的资源，比如代码段、堆空间、数据段、打开的文件等，但每个线程都有自己独立的栈空间

#### 互斥锁


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/code/4-os/os-0c1/#and" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">



### 互斥锁&自旋锁

当已经有一个线程加锁后，其他线程加锁则就会失败

*互斥锁*加锁失败后，线程会释放 CPU 给其他线程
*自旋锁*加锁失败后，线程会占据 CPU 忙等待直到拿到锁

互斥锁是一种独占锁，加锁失败时由操作系统内核实现阻塞，

互斥锁存在两次线程上下文切换，因此当加锁执行的代码执行时间较短时，应选用自旋锁减小开销

自旋锁通过 CPU 提供的 CAS 函数完成加锁
1. 查看锁的状态
2. 如果锁处于空闲状态，将锁设置为当前线程持有

CAS 函数将两个步骤合并成一条硬件级指令，形成**原子指令**，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行
CAS 本身为乐观锁，但自旋锁为借助 CAS 实现的悲观锁


在单核 CPU 上使用自旋锁需要抢占式的调度器(即不断通过时钟中断一个线程，运行其他线程)，因为一个自旋的线程永远不会放弃 CPU


</div></div>


#### 条件变量

[条件变量为什么要和互斥锁一起使用_条件变量为什么要和锁一起用_一只牛_007的博客-CSDN博客](https://blog.csdn.net/yizhiniu_xuyw/article/details/109635912)

条件变量是利用线程间共享的全局变量进行同步的一种机制，用于自动阻塞一个线程，直到某特殊情况发生为止

一个条件变量可以阻塞多个线程，这些线程会组成一个等待队列，当条件成立时，条件变量可以解除线程的“被阻塞状态”
也就是说，条件变量可以完成以下两项操作：
- 阻塞线程，直至接收到“条件成立”的信号
- 向等待队列中的一个或所有线程发送“条件成立”的信号，解除它们的“被阻塞”状态

为了避免多线程之间发生“抢夺资源”的问题，条件变量在使用过程中必须和一个互斥锁搭配使用
当条件不满足时，线程往往解开相应的互斥锁并等待条件发生变化，一旦其他的某个线程改变了条件变量，将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程，这些线程将重新锁定互斥锁并重新测试条件是否满足，如果满足则解除阻塞，不满足则继续阻塞等待唤醒

#### 信号量

同进程信号量

## 进程 VS 线程

- **进程是资源(包括内存、打开的文件等)分配的基本单位，线程是 CPU 调度的基本单位**
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系
- 线程能减少并发执行的时间和空间开销

线程开销减少：
- 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们
- 线程的终止时间比进程快，因为线程释放的资源相比进程少很多
- 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间(虚拟内存共享)，这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的
- 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了

## 调度

操作系统通过**调度程序(scheduler)** 选择运行的程序

### 调度时机

在进程的生命周期中，当进程状态变化时会触发一次调度

如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类：
- **非抢占式调度算法**挑选一个进程运行，直到该进程被阻塞或者进程退出才会调用另外一个进程，忽视时钟中断事件
- **抢占式调度算法**挑选一个进程运行，在时间间隔的末端发生**时钟中断**，把 CPU 控制返回给调度程序进行调度，如果此时该进程仍在运行，调度程序将该进程挂起并从就绪队列中挑选另外一个进程运行，也就是常说的**时间片机制**

### 调度原则

_原则一_：如果运行的程序，发生了 I/O 事件请求，进程阻塞等待硬盘的数据返回，会造成 CPU 突然的空闲
所以，**为了提高 CPU 利用率，在 I/O 事件请求致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行**

_原则二_：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量(CPU 在单位时间内完成的进程数量)的降低
所以，**要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量**

_原则三_：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间，进程的周转时间越小越好
所以，**如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生**

_原则四_：处于就绪队列的进程不能等太久，等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行
所以，**就绪队列中进程的等待时间也是调度程序所需要考虑的原则**

_原则五_：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了
所以，**对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则**

针对上面的五种调度原则，总结如下：
- **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，提高 CPU 的利用率
- **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量
- **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好
- **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意
- **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准

### 调度算法

#### 先来先服务

*先来先服务(FCFS)算法*每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行

当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业
FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统

#### 最短作业优先

*最短作业优先(SJF)调度算法*优先选择运行时间最短的进程来运行，有助于提高系统的吞吐量

对长作业不利，当就绪队列有非常多的短作业时会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行

#### 高响应比优先

*高响应比优先 (HRRN)调度算法*权衡了短作业和长作业，每次进行进程调度时，先计算*响应比优先级*，然后把响应比优先级最高的进程投入运行
$$ 优先级 = \frac{等待时间+要求服务时间}{要求服务时间} $$
- 两个进程的等待时间相同时，要求的服务时间越短，优先级越高，这样短作业的进程容易被选中运行
- 两个进程要求的服务时间相同时，等待时间越长，优先级就越高，兼顾到了长作业进程，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会

实际情况下进程的要求服务时间无法确定，因此高响应比优先调度算法属于理想型算法

#### 时间片轮转

*时间片轮转(RR)调度算法*是最古老、最简单、最公平且使用最广的算法
每个进程被分配一个时间段，称为时间片，允许该进程在该时间段中运行
- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换

时间片的长度就是一个很关键的点：
- 如果时间片设得太短会导致过多的进程上下文切换，降低 CPU 效率
- 如果设得太长可能引起对短作业进程的响应时间变长

一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值

#### 最高优先级

*最高优先级(\HPF)调度算法*从就绪队列中选择最高优先级的进程进行运行

进程的优先级可以分为：
- **静态优先级**：创建进程时候优先级已确定，然后整个运行时间优先级都不会变化
- **动态优先级**：根据进程运行情况动态调整优先级，比如进程运行时间增加，则降低其优先级，进程等待时间(就绪队列的等待时间)增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级

该算法也有两种处理优先级高的方法：
- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行

但是 HPF 算法可能会导致低优先级的进程永远不会运行

#### 多级反馈队列

*多级反馈队列(Multilevel Feedback Queue)调度算法*是「时间片轮转算法」和「最高优先级算法」的综合和发展
多级表示有多个队列，每个队列优先级从高到低，同时**优先级越高时间片越短**
反馈表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列

新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度
如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成
如果进程在其时间片内主动释放 CPU，则优先级不变

问题
- 饥饿：如果系统有过多交互型工作，就会不断加入优先级高队列占用 CPU，导致位于优先级低队列的长工作永远无法得到 CPU
- 愚弄调度程序：用户控制进程在时间片用完之前，调用一个 I/O 操作(比如访问一个无关的文件)，从而主动释放 CPU，如此便可以始终保持在高优先级，占用更多的 CPU 时间，极端情况下(比如每运行 99%的时间片时间就主动放弃一次 CPU)可以几乎独占 CPU

解决方法：
- *priority boost 机制*，一段时间后将所有任务都提升到最高优先级队列，防止一直来新的任务让低优先级的长任务饿死
- 一旦工作用完了其在某一层中的时间配额(无论中间主动放弃了多少次 CPU)，就降低其优先级(移入低一级队列)

## 中断

中断是系统用来响应硬件设备请求的一种机制
操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求

中断处理程序应尽可能快的执行完以减少对正常进程运行调度的影响
> 中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失

### 软中断

linux 将中断分为硬中断和软中断两部分以解决中断处理程序执行过长和中断丢失的问题

- 硬中断直接处理硬件请求，用于快速处理中断
  - 硬中断会打断 CPU 正在执行的任务以立即执行中断处理程序
- 软中断延迟处理未完成的相对耗时且复杂的工作，一般以*内核线程*方式运行

linux 中的软中断包括网络收发、定时、调度、RCU 锁等各种类型

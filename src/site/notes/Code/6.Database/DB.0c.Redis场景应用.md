---
{"dg-publish":true,"permalink":"/Code/6.Database/DB.0c.Redis场景应用/","title":"Redis 场景应用","noteIcon":""}
---


# Redis 场景应用

## 常见数据类型的场景应用

> [Redis 常见数据类型和应用场景 | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/redis/data_struct/command.html)

### String

#### 缓存对象

#### 常规计数

因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等

#### 分布式锁

SET 命令有个 NX 参数可以实现**key 不存在才插入**，可以用它来实现分布式锁：
- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败

一般而言，还会对分布式锁加上过期时间

#### 共享 Session 信息

### List

#### 消息队列

消息队列在存取消息时，必须要满足三个需求，分别是**消息保序、处理重复的消息和保证消息可靠性**。

Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求

### Hash

#### 购物车

以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素

涉及的命令如下：
- 添加商品：`HSET cart:{用户id} {商品id} 1`
- 添加数量：`HINCRBY cart:{用户id} {商品id} 1`
- 商品总数：`HLEN cart:{用户id}`
- 删除商品：`HDEL cart:{用户id} {商品id}`
- 获取购物车所有商品：`HGETALL cart:{用户id}`

当前仅仅是将商品ID存储到了Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息

### Set

#### 点赞

Set 类型可以保证一个用户只能点一个赞

#### 共同关注

Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号

#### 抽奖活动

存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次

### ZSet

#### 排行榜

有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等

#### 电话/姓名排序

使用有序集合的 `ZRANGEBYLEX` 或 `ZREVRANGEBYLEX` 可以帮助我们实现电话号码或姓名的排序

### Bitmap

#### 签到统计

在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态

## 主从复制

> [主从复制是怎么实现的？ | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/redis/cluster/master_slave_replication.html)

通过将数据备份到其他服务器上可避免**单点故障问题**

Redis 提供**主从复制模式**以解决多服务器间的数据一致性问题

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器
从服务器一般只读，同时接受主服务器同步过来的写操作命令并执行

Redis 使用 `replicaof` 命令形成主服务器和从服务器的关系
```
# 在slave服务器执行命令
replicaof {master 的 IP 地址} {slave 的 Redis 端口号}
```

主从复制共有三种形式：**全量复制、基于长连接的命令传播、增量复制**

### 全量复制

主从服务器间的*第一次同步的过程*可分为三个阶段：
1. 建立链接、协商同步
    1. 从服务器向主服务器发送 `psync` 命令
    2. 主服务器返回 `FULLRESYNC` 响应命令，表示采用**全量复制方式**同步数据
2. 主服务器同步数据给从服务器
    1. 主服务器执行 BGSAVE 命令生成 RDB 文件并发送给从服务器
    2. 从服务器收到后清空当前数据，载入 RDB 文件，同时主服务器将以下三个时期中收到的写操作命令，写入到 *replication buffer* 缓冲区里
        - 主服务器生成 RDB 期间
        - 主服务器发送 RDB 期间
        - 从服务器加载 RDB 期间
    3. 从服务器完成载入 RDB 后回复确认消息给主服务器
3. 主服务器发送新写操作命令给从服务器
    1. 主服务器将 `replication buffer` 缓冲区内记录的写操作命令发送给从服务器
    2. 从服务器依次执行命令，完成第一次同步

从服务器发送给主服务器的 `psync` 命令中包含*主服务器的 runID* 和*复制进度 offset*
- `runID`，每个 Redis 服务器启动时自动生产一个随机的唯一自我标识 ID ，第一次同步时从服务器不知道主服务器的 run ID，所以将其设置为 `?`
- `offset`，表示复制的进度，第一次同步时，其值为 -1

> ![ea4f7e86baf2435af3999e5cd38b6a26.png (1080×555) (xiaolincoding.com)](https://cdn.xiaolincoding.com//mysql/other/ea4f7e86baf2435af3999e5cd38b6a26.png)

### 基于长连接的命令传播

主从服务器在完成第一次同步后维护一个 *TCP 长连接*
主服务器通过该连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，保持与主服务器的数据库状态相同

通过*基于长连接的命令传播*保证了第一次同步后的主从服务器的数据一致性

*过期 key*：主节点处理了一个 key 或者通过淘汰算法淘汰了一个 key，这个时间主节点模拟一条 del 命令发送给从节点，从节点收到该命令后，就进行删除 key 的操作

### 增量复制

主从服务器重连时可以采用*增量复制*的方式继续同步，仅将网络断开期间主服务器接收到的写操作命令同步给从服务器

增量复制步骤：
1. 从服务器在恢复网络后发送 `psync` 命令给主服务器
2. 主服务器用 `CONTINUE` 响应命令，表示采用**增量复制的方式**同步数据
3. 主服务器发送网络断开期间主服务器接收的写操作命令，从服务器执行命令

具体的增量数据通过*repl_backlog_buffer*和*replication offset*确认

repl_backlog_buffer 是一个 **环形**缓冲区，Redis 主节点每次收到写命令之后，先写到内部的repl_backlog_buffer缓冲区，然后**异步发送给从节点**
主节点使用 `master_repl_offset` 标记缓冲区中当前写入的位置，从节点使用 `slave_repl_offset` 标记缓冲区中当前读出的位置

增量复制过程中从服务器通过 `psync` 命令发送自己的复制偏移量 `slave_repl_offset`，主服务器根据 `master_repl_offset` 和 `slave_repl_offset` 之间的差距决定执行哪种同步操作：
- `slave_repl_offset` 还在 `repl_backlog_buffer` 缓冲区里，采用增量同步
- `slave_repl_offset` 已不在缓冲区里，采用全量同步

> ![2db4831516b9a8b79f833cf0593c1f12.png (1080×380) (xiaolincoding.com)](https://cdn.xiaolincoding.com//mysql/other/2db4831516b9a8b79f833cf0593c1f12.png)

为了避免在网络恢复时主服务器频繁进行全量同步，应该使 `repl_backlog_buffer` 缓冲区大小尽可能大

#### Replication buffer VS repl backlog buffer

- 出现阶段与数量不同：
    - repl backlog buffer 是在增量复制阶段出现，一个主节点只分配一个 repl backlog buffer
    - replication buffer 是在全量复制阶段和增量复制阶段都会出现，主节点会给每个新连接的从节点，分配一个 replication buffer
- 溢出处理不同：
    - repl backlog buffer 环形缓冲区溢出的新数据会直接覆盖起始位置数据
    - replication buffer 溢出导致连接断开，删除缓存，从节点重新连接，重新开始全量复制

### 异常

#### 主从断连

Redis 通过互相的 ping-pong 心跳检测机制检测断连，如果一半以上的节点去 ping 一个节点的时候没有收到 pong 回应，集群认为这个节点挂掉并断开与这个节点的连接

- Redis 主节点默认每隔 10 秒对从节点发送 ping 命令判断存活性和连接状态，可通过参数 `repl-ping-slave-period` 控制发送频率
- Redis 从节点每隔 1 秒向主节点发送 `replconf ack{offset}` 命令上报自身当前的复制偏移量
    - 实时监测主从节点网络状态
    - 检查复制数据是否丢失，如果从节点数据丢失，再从主节点的replication buffer缓冲区中拉取丢失数据

#### 主从数据不一致

主从节点之间的命令复制异步进行，因此无法保证主从数据的强一致性

解决方法：
- 保证主从服务器连接状态良好
- 使用外部程序检查主从服务器 `repl offset` 差值，对客户端屏蔽差值较大的从服务器

#### 主从数据丢失

主从切换过程中，产生数据丢失的情况有两种：
- 异步复制同步丢失
- 集群产生脑裂数据丢失

##### 异步复制命令丢失

问题：
主服务器已进行写操作命令但还未将命令异步发送给从服务器时宕机

解决方案：
通过参数 `min-slaves-max-lag` 定义主从服务器间的最大差异时间，在主从节点间数据差异过大(所有的从节点数据复制和同步的延迟都超过了设定值)时主服务器拒绝写入新请求
客户端可将数据暂时写入本地缓存或消息队列中

##### 集群脑裂导致数据丢失

> [xiaolincoding.com](https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E9%9B%86%E7%BE%A4%E4%BA%A7%E7%94%9F%E8%84%91%E8%A3%82%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1)

问题：
主节点与从节点失联但与客户端连接正常，重新上线时变为新主节点的从节点，清空数据重新全量同步，导致失联后客户端写入的数据丢失，

解决方案：
当主节点发现**从节点下线的数量太多**或**网络延迟太大**时，主节点会禁止写操作，直接把错误返回给客户端

### 主服务器减压

问题：
- 从服务器数量多时，主服务器忙于使用 fork()创建子进程，进而导致主线程阻塞
- 传输 RDB 文件占用主服务器网络带宽，影响主服务器响应命令
解决方法：
- 令从服务器创建从服务器，分担主服务器压力

> ![4d850bfe8d712d3d67ff13e59b919452.png (1052×632) (xiaolincoding.com)|600](https://cdn.xiaolincoding.com//mysql/other/4d850bfe8d712d3d67ff13e59b919452.png)

## 哨兵

哨兵的作用是实现**主从节点故障转移**，哨兵监测主节点是否存活，如果发现主节点挂了，哨兵选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端

> ![|675](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB.png)

哨兵主要负责*监控*、*选主*、*通知*

### 监控

哨兵每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行
哨兵将没有在规定的时间内响应 PING 命令的节点标记为*主观下线*，规定时间通过配置项 `down-after-milliseconds` 参数设定

哨兵用多个节点部署成*哨兵集群*(最少三台机器)以减少误判，避免因为单个哨兵自身网络状况不好而误判主节点下线的情况
*客观下线*仅针对主节点
1. 当一个哨兵判断主节点*主观下线*后，向其他哨兵发起询问命令
2. 其他哨兵根据自身连接情况对该判断投票
3. 赞同票数达到设定值 `quorum` 时，主节点被1中的哨兵标记为*客观下线*
    - `quorum` 的值一般设置为哨兵个数的1/2加1

### 选主

#### 哨兵leader

在哨兵集群中，由 leader 哨兵进行主从故障转移
Leader 通过投票选举：
1. 在主节点客观下线后，标记主节点的哨兵成为 leader 候选者
2. 候选者会向其他哨兵发送命令，表明希望成为 leader 来执行主从切换，并让所有其他哨兵对它进行投票
    - 每个哨兵只有一次投票机会，投给先收到其投票请求的候选者，候选者给自己投票
3. 满足条件的候选者成为 leader
    - 拿到半数以上的赞成票
    - 拿到的票数大于等于哨兵配置文件中的 `quorum` 值

哨兵节点应设置为奇数个，同时 `quorum` 的值设置为哨兵个数的1/2加1以保证主节点客观下线后能够选出哨兵 leader

#### 选出新主节点

> ![|500](https://cdn.Xiaolincoding.Com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E9%80%89%E4%B8%BB%E8%BF%87%E7%A8%8B.webp)

*优先级*：Redis 通过配置项` slave-priority` 给从节点设置优先级

选举出从节点后，哨兵 leader 向被选中的从节点发送 `SLAVEOF no one` 命令，让这个从节点解除从节点的身份，将其变为新主节点
之后哨兵 leader 以每秒一次的频率向被升级的从节点发送 `INFO` 命令，并观察命令回复中的角色信息，当被升级节点的*角色信息*从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了

正常状态下，哨兵以每 10 s 一次的频率向主节点发送 `INFO` 命令来获取所有从节点的信息

### 通知

被选中的从节点顺利升级后，哨兵 leader 向所有从节点发送 `SLAVEOF` 命令，让它们成为新主节点的从节点

哨兵集群通过*发布者/订阅者机制*向客户端提供新主节点的信息，主从切换完成后，哨兵就会向 `+switch-master` 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了

哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件
> ![|600](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E5%93%A8%E5%85%B5%E9%A2%91%E9%81%93.webp)

最后哨兵集群监视旧主节点，当其重新上线时向其发送 `SLAVEOF` 命令，让其成为新主节点的从节点，结束主从节点的故障转移的工作

### 哨兵集群

哨兵配置
```
sentinel monitor {master-name} {ip} {redis-port} {quorum} 
```

哨兵节点之间**通过 Redis 的发布者/订阅者机制相互发现**

在主从集群中，主节点上有一个名为 `__sentinel__:hello` 的频道，哨兵节点将自己的 IP 地址和端口信息发布到该频道上后，其他哨兵就可以获取这些信息，从而建立网络连接

## 分布式锁

Redis 分布式锁的实现通常使用 SetNX 命令，当 key 不存在时设置 key

val 为 uuid，expiration 为5s

过期时间避免原本加锁的 worker 崩溃后锁永远无法释放

锁值为 uuid 保证了锁的可识别性，在释放锁的时候通过检查 val 避免释放别人的锁
释放锁过程：
1. 检测锁值是否为自己的 uuid
2. 是则释放锁

实现基于 Redis 的公平锁，为等待锁的进程分配优先级，确保长时间等待的进程能够优先获得锁，解决饥饿问题

## 缓存

Redis 可作为 Mysql 的缓存，存储 Mysql 的热点数据

服务端缓存：在访问 DB 后将请求参数作为 key，回包内容作为 value 进行缓存
客户端缓存：对服务端 RPC 调用后，将结果存储在客户端

### 缓存模式

> [数据库和缓存如何保证一致性？ | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html)

#### Cache Aside 旁路缓存

最常见的策略

读策略：
1. 应用服务查询数据是否在缓存上
2. 如果在，就用缓存数据直接打包返回
3. 如果不存在，从数据库查询，并放到缓存中

除了查库后加载这种模式，如果业务有需要，还可以预加载数据到缓存

写策略：
1. 先更新数据库
2. 后删除缓存

#### Read/Write Through  读/写穿透

读穿透：
应用服务不和缓存直接交互而是访问数据服务，数据服务查询数据是否在缓存上，不在则从数据库查询

写穿透：
所有的写操作都经过缓存，每次向缓存中写数据的时候，缓存会把数据持久化到对应的数据库中去，且这两个操作都在一个事务中完成
因此，只有两次都写成功了才是最终写成功了

- 在更新缓存前先加个**分布式锁**，保证同一时间只运行一个请求更新缓存，就不会产生并发问题，引入了锁对于写入性能会带来影响
- 在更新完缓存时，给缓存加上较短的**过期时间**，即使出现缓存不一致的情况，缓存的数据也会很快过期

#### Write Behind

Write Through 的异步更新版本，在写入一段时间后将数据一起写入数据库

### 缓存一致性

 > [Redis 缓存更新一致性 - -Finley- - 博客园 (cnblogs.com)](https://www.cnblogs.com/Finley/p/12615111.html)

完全避免缓存不一致只有使用锁，包括 CAS 乐观锁，分布式锁（悲观锁），分布式事务
实践过程中也可以使用延时双删极大的降低不一致概率
订阅 binglog 可以避免写线程相互竞争, 但避免不了读写线程竞争

#### 不完全解决

##### 过期依赖

更新时仅更新数据库不处理缓存，等待 Redis 缓存过期失效后从 Mysql 拉取新数据

优点：
- 开发成本低
- 管理成本低
缺点：
- 过期时间的设定考验业务能力，太短缓存频繁失效，太长缓存不一致时间长

##### 删除缓存

删除缓存可以保证缓存中不因为更新出现错误数据，但可能因为删除失败而使得旧数据长时间保留

进一步可以采用*过期时间*，*重试机制*或者*延时双删*进行弥补
- 通过为缓存设立过期时间弥补删除缓存失败带来的更新失败
- 重试机制引入消息队列，将删除缓存加入消息队列确保删除成功
  - 如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，如果重试超过一定次数还是没有成功，就需要向业务层发送报错信息
  - 如果删除缓存成功，把数据从消息队列中移除，避免重复操作
- 延时双删令写线程等待一段时间基本确认读线程都结束后再次删除缓存

> [!quote] 为什么是删除缓存，而不是更新缓存呢？
> 删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小
> 在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。比如商品详情信息，在底层可能会关联商品表、价格表、库存表等，如果更新了一个价格字段，那么就要更新整个数据库，还要关联的去查询和汇总各个周边业务系统的数据，这个操作会非常耗时
> 从另外一个角度，不是所有的缓存数据都是频繁访问的，更新后的缓存可能会长时间不被访问，所以说，从计算资源和整体性能的考虑，更新的时候删除缓存，等到下次查询命中再填充缓存，是一个更好的方案
> 系统设计中有一个思想叫 Lazy Loading，适用于那些加载代价大的操作，删除缓存而不是更新缓存，就是懒加载思想的一个应用

##### 订阅 binlog

将搭建的消费服务作为 Mysql 的一个从服务器，订阅 Mysql 的 binlog 日志，解析日志内容后更新至 redis

#### 锁

##### CAS

CAS 乐观锁当且仅当客户端最后一次取值后该 key 没有被其他客户端修改的情况下，才允许当前客户端将新值写入

##### 分布式锁

在每次更新前获取分布式排他锁保证一致性

### 缓存异常

> [什么是缓存雪崩、击穿、穿透？ | 小林coding ](https://xiaolincoding.com/redis/cluster/cache_problem.html)

缓存异常的三个常见问题分别是**缓存雪崩、缓存击穿、缓存穿透**

通常会给缓存数据设置过期时间，缓存过期后重新从数据库中取数据并更新至缓存

#### 缓存雪崩

*缓存雪崩*指同一时间发生大量缓存数据的过期或 Redis 故障宕机时，大量请求直接访问数据库导致数据库压力过大崩溃

解决方法
- 大量数据过期
  - 根据业务数据有效期进行分类错峰，比如A类90分钟，B类80分钟，C类70分钟
  - 过期时间使用固定时间+随机值的形式，稀释集中到期的 key 的数量
  - 超热数据永不过期(人工/脚本维护刷新)
- 故障宕机
  - 服务熔断/请求限流
  - 通过主从节点方式构建 Redis 高可靠集群

#### 缓存击穿

*缓存击穿*指缓存中某个热点数据过期后被大量的请求访问，高并发请求直接访问数据库导致数据库崩溃

解决方案：
- 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值
- 设置热点数据永不过期，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间
- 服务熔断/请求限流

#### 缓存穿透

*缓存穿透*指大量请求访问不存在的数据导致数据库压力骤增

解决方案：
- 限制非法请求，在 API 入口处对其进行检测拦截
- 缓存空值或默认值，针对查询的不存在数据在缓存中设置空值或默认值
- 使用**布隆过滤器**，在写入数据库时进行标记，业务线程确认缓存失效时可快速判断数据是否存在，避免访问数据库

布隆过滤器基于哈希实现，存在 hash 冲突的可能
布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据
